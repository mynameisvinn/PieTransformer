{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[example](http://jalammar.github.io/illustrated-transformer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def fetch():\n",
    "    \"\"\"generate XOR sequence.\n",
    "    \"\"\"\n",
    "    a = random.choice([0, 1])\n",
    "    b = np.random.uniform(0, 1)\n",
    "    c = np.random.uniform(0, 1)\n",
    "    d = np.random.uniform(0, 1)\n",
    "    X = [a, b, c, d]\n",
    "    \n",
    "    if a == 0:\n",
    "        y = 0\n",
    "    else:\n",
    "        y = 1\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()  # this is how objects that inherit from parent classes are instantiated\n",
    "        self.query_matrix = nn.Parameter(torch.randn(1))\n",
    "        self.key_matrix = nn.Parameter(torch.randn(1))\n",
    "        self.fc1 = nn.Linear(in_features=4, out_features=4)\n",
    "        self.fc2 = nn.Linear(in_features=4, out_features=2)\n",
    "\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        \n",
    "        # generate a new embedding for each token in the list\n",
    "        new_input_seq = []\n",
    "        for token in input_seq:\n",
    "            \n",
    "            # generate query vector from query matrix\n",
    "            q = self.query_matrix * token\n",
    "            \n",
    "            # track list of scores\n",
    "            scores = []\n",
    "        \n",
    "            # then compute scores by multiplying query vector by key vector of every element\n",
    "            for element in input_seq:\n",
    "                \n",
    "                # for each element in input_seq, generate a key vector from the key matrix\n",
    "                k = self.key_matrix * element\n",
    "                \n",
    "                # calculate score vector\n",
    "                s = q * k\n",
    "                scores.append(s)\n",
    "    \n",
    "            # softmax score vector to create mask\n",
    "            mask = F.softmax(torch.stack(scores), dim=0)\n",
    "            \n",
    "            # now multiply each token in the original list by its corresponding element in its mask\n",
    "            new_embedding = 0\n",
    "            for pair in zip(input_seq, mask):\n",
    "                new_embedding += pair[0] * pair[1]\n",
    "            new_input_seq.append(new_embedding)\n",
    "        \n",
    "        # then, lets see if we can classify better with attention\n",
    "        new_input_seq = torch.stack(new_input_seq).reshape(1, len(new_input_seq))\n",
    "        x = self.fc1(new_input_seq)\n",
    "        x = self.fc2(x)\n",
    "        y_prob = F.softmax(x, dim=1)\n",
    "        return y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = Net()\n",
    "optimizer = optim.SGD(net1.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0.3417277474918079, 0.4525821282146074, 0.18839683301654941]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4245, 0.5755]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # train\n",
    "    for _ in range(1000):\n",
    "        # X_train, y_train = fetch()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net1(X_train)\n",
    "        loss = F.nll_loss(outputs[0].reshape(1, 2), torch.tensor([y_train]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # test\n",
    "    acc = 0\n",
    "    for _ in range(100):\n",
    "        # X_test, y_test = fetch() \n",
    "        outputs = net1(X_train)\n",
    "        pred = int(torch.argmax(outputs[0]))\n",
    "        if pred == y_train:\n",
    "            acc += 1\n",
    "    print(acc/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.1081e-07, 1.0000e+00]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
