{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating the dataset\n",
    "we generate {X, y} from scratch. $X$ is a ndim array of features. $y$ is the corresponding target, and equals XOR of $X_1$ and $X_2$ (ie $y$ is true if either $X_1$ or $X_2$ is true, otherwise it is false). all other features in $X$ is random uniform noise.\n",
    "\n",
    "## which features should the attention vector attend to?\n",
    "since $y$ is XOR of $X_1$ and $X_2$, we would expect the attention vector to attend to both $X_1$ and $X_2$. (knowing either $X_1$ and $X_2$ is insufficient.)\n",
    "\n",
    "moreover, since all other features in $X$ is random noise - and therefore are uninformative features - we would expect attention vector to ignore all other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data from scratch\n",
    "n_samples = 10000\n",
    "n_features = 16\n",
    "\n",
    "# attention vector has n_hidden dim, which must equal input ndim since it masks inputs\n",
    "n_hidden = n_features\n",
    "\n",
    "X = np.random.uniform(low=-5, high=5, size=(n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set X1 and X2 to either 0 or 1\n",
    "X[:, 0] = X[:, 0] > 0  # feature 0\n",
    "X[:, 1] = X[:, 1] > 0  # feature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate corresponding target y data\n",
    "y = np.logical_xor(X[:, 0], X[:, 1]) * 1  # y = XOR(X1, X2)\n",
    "\n",
    "n_classes = 2\n",
    "y = np.eye(n_classes)[y]  # convert y to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5, 0]\n",
    "X[:5, 1]\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers):\n",
    "        super().__init__()\n",
    "        # Input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "\n",
    "    def forward(self, x, y):     \n",
    "        for each in self.hidden_layers:\n",
    "            z = F.softmax(each(x))\n",
    "            x = torch.mul(z, x)\n",
    "        #x = self.output(x)\n",
    "        return self.output(x)\n",
    "    \n",
    "    def att_vector(self, x, y):\n",
    "        for each in self.hidden_layers:\n",
    "            z = F.softmax(each(x))\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(n_features, n_classes, [n_hidden])\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, inputs, labels, criterion, optimizer, epochs, batch_size, print_every):\n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        mb_indices = np.random.choice(X.shape[0], batch_size)\n",
    "        \n",
    "        X_train = X[mb_indices]\n",
    "        y_train = y[mb_indices]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model.forward(X_train, y_train)\n",
    "        #print(output.size(), y_train.size())\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if e%print_every == 0:\n",
    "            model.eval()\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every))\n",
    "                \n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q1park/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5000..  Training Loss: 0.001.. \n",
      "Epoch: 500/5000..  Training Loss: 0.419.. \n",
      "Epoch: 1000/5000..  Training Loss: 0.077.. \n",
      "Epoch: 1500/5000..  Training Loss: 0.042.. \n",
      "Epoch: 2000/5000..  Training Loss: 0.029.. \n",
      "Epoch: 2500/5000..  Training Loss: 0.021.. \n",
      "Epoch: 3000/5000..  Training Loss: 0.018.. \n",
      "Epoch: 3500/5000..  Training Loss: 0.014.. \n",
      "Epoch: 4000/5000..  Training Loss: 0.013.. \n",
      "Epoch: 4500/5000..  Training Loss: 0.013.. \n"
     ]
    }
   ],
   "source": [
    "train(model, X, y, criterion, optimizer, 5000, 64, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q1park/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.04527778e-01, 2.54949094e-01, 4.40589143e-02, 3.79840961e-02,\n",
       "       2.77683146e-02, 4.98704459e-03, 1.95136788e-02, 4.71203965e-02,\n",
       "       4.11730033e-02, 1.55679578e-05, 4.61321854e-02, 4.44755407e-02,\n",
       "       2.72620119e-02, 5.23196867e-02, 2.26416478e-02, 2.50710391e-02])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_vector = model.att_vector(X, y)\n",
    "np.mean(attention_vector.detach().numpy(), axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# which features should we attend to?\n",
    "plt.bar(x = np.arange(n_features), height = np.mean(attention_vector.detach().numpy(), axis=0));\n",
    "plt.xlabel(\"feature\");\n",
    "plt.ylabel(\"attention\");\n",
    "plt.title(\"attention vector\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
